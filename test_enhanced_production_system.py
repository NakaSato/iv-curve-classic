#!/usr/bin/env python3
"""
Enhanced Production System Test with Multi-String Support
Test all analysis types including the new 32-string analyzer
"""

import os
import asyncio
import json
from pathlib import Path
from datetime import datetime
import logging
from production_dual_string_system import ProductionDualStringSystem

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

async def test_enhanced_production_system():
    """Test the enhanced production system with multi-string support"""
    
    print("ğŸš€ Enhanced Production System Test - Multi-String Support")
    print("=" * 70)
    
    # Initialize production system
    config_file = "production_config.ini"
    system = ProductionDualStringSystem(config_file=config_file)
    
    print(f"âœ… System initialized with multi-string support")
    print(f"ğŸ”Œ Supported analysis types:")
    print(f"   â€¢ enhanced_iv - Fast I-V curve analysis")
    print(f"   â€¢ ai_powered - AI-powered analysis with ML")
    print(f"   â€¢ multi_string - 32-string comprehensive analysis")
    print(f"   â€¢ comprehensive - Combined analysis")
    
    # Test 1: Multi-String Analysis with Generated Data
    print("\nğŸ”Œ Test 1: Multi-String Analysis (32 Strings)")
    print("-" * 50)
    
    # First, generate multi-string test data
    print("ğŸ“Š Generating 32-string test data...")
    from test_multi_string_analyzer import generate_multi_string_iv_data
    
    try:
        test_data_file, _ = generate_multi_string_iv_data(
            num_strings=32,
            num_points=120,
            output_file="production_test_32string_data.csv"
        )
        
        print(f"âœ… Generated test data: {test_data_file}")
        
        # Run multi-string analysis
        system_id = "MULTI_STRING_SYSTEM_01"
        print(f"ğŸ” Running multi-string analysis on {system_id}...")
        
        result = await system.analyze_system(
            system_id=system_id,
            data_file=test_data_file,
            analysis_type="multi_string"
        )
        
        if result['status'] == 'success':
            print(f"âœ… Multi-string analysis completed successfully!")
            print(f"â±ï¸ Duration: {result['duration_seconds']:.1f}s")
            
            # Extract key results
            results = result['results']
            if 'summary' in results:
                summary = results['summary']
                print(f"âš¡ Total Power: {summary.get('total_power', 0):.0f} W")
                print(f"ğŸ“Š System Efficiency: {summary.get('efficiency', 0):.1f}%")
                print(f"ğŸ”Œ Active Strings: {results.get('active_strings', 0)}")
                print(f"ğŸ’¡ Recommendations: {len(summary.get('recommendations', []))}")
        else:
            print(f"âŒ Multi-string analysis failed: {result.get('error', 'Unknown error')}")
            
    except Exception as e:
        print(f"âš ï¸ Multi-string test failed: {e}")
    
    # Test 2: Compare Analysis Types
    print("\nğŸ“ˆ Test 2: Analysis Type Comparison")
    print("-" * 50)
    
    data_file = "inverter/INVERTER_01_2025-04-04_2025-04-05.csv"
    if os.path.exists(data_file):
        analysis_types = ["enhanced_iv", "ai_powered"]
        system_id = "INVERTER_01"
        
        comparison_results = {}
        
        for analysis_type in analysis_types:
            print(f"ğŸ” Running {analysis_type} analysis...")
            
            try:
                result = await system.analyze_system(
                    system_id=f"{system_id}_{analysis_type.upper()}",
                    data_file=data_file,
                    analysis_type=analysis_type
                )
                
                if result['status'] == 'success':
                    comparison_results[analysis_type] = {
                        'duration': result['duration_seconds'],
                        'success': True
                    }
                    print(f"âœ… {analysis_type}: {result['duration_seconds']:.1f}s")
                else:
                    comparison_results[analysis_type] = {
                        'duration': 0,
                        'success': False,
                        'error': result.get('error', 'Unknown')
                    }
                    print(f"âŒ {analysis_type}: Failed - {result.get('error', 'Unknown')}")
                    
            except Exception as e:
                print(f"âŒ {analysis_type}: Exception - {e}")
                comparison_results[analysis_type] = {
                    'duration': 0,
                    'success': False,
                    'error': str(e)
                }
        
        # Show comparison summary
        print(f"\nğŸ“Š Analysis Performance Comparison:")
        for analysis_type, results in comparison_results.items():
            status = "âœ… Success" if results['success'] else "âŒ Failed"
            duration = f"{results['duration']:.1f}s" if results['success'] else "N/A"
            print(f"   {analysis_type:15} | {status:10} | {duration:>8}")
    
    # Test 3: Fleet Status with Mixed Systems
    print("\nğŸŒ Test 3: Enhanced Fleet Status")
    print("-" * 50)
    
    try:
        fleet_status = system.get_fleet_status()
        
        print(f"ğŸ¢ Enhanced Fleet Overview:")
        print(f"   Total Systems: {fleet_status['total_systems']}")
        print(f"   Average Health: {fleet_status['average_health']:.1f}%")
        print(f"   Average Efficiency: {fleet_status['average_efficiency']:.1f}%")
        print(f"   Active Alerts: {fleet_status['total_alerts']}")
        
        # Show system breakdown
        if 'systems_by_status' in fleet_status:
            print(f"   Status Breakdown:")
            for status, count in fleet_status['systems_by_status'].items():
                print(f"     {status}: {count} systems")
        
    except Exception as e:
        print(f"âŒ Fleet status retrieval failed: {e}")
    
    # Test 4: Advanced Dashboard Creation
    print("\nğŸ“Š Test 4: Enhanced Dashboard Generation")
    print("-" * 50)
    
    try:
        dashboard_file = system.create_fleet_dashboard()
        if dashboard_file:
            print(f"ğŸ“ˆ Enhanced fleet dashboard created: {dashboard_file}")
            
            if os.path.exists(dashboard_file):
                file_size = os.path.getsize(dashboard_file) / 1024  # KB
                print(f"ğŸ“ Dashboard size: {file_size:.1f} KB")
        else:
            print(f"âš ï¸ Dashboard creation returned empty filename")
        
    except Exception as e:
        print(f"âŒ Dashboard generation failed: {e}")
    
    # Test 5: Database Analysis
    print("\nğŸ’¾ Test 5: Enhanced Database Analysis")
    print("-" * 50)
    
    try:
        import sqlite3
        conn = sqlite3.connect(system.db_path)
        cursor = conn.cursor()
        
        # Get detailed database statistics
        tables = ['system_status', 'alerts', 'analysis_results', 'performance_metrics']
        total_records = 0
        
        print(f"ğŸ“‹ Enhanced Database Statistics:")
        for table in tables:
            try:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
                total_records += count
                print(f"   {table:20} | {count:>6} records")
                
                # Show recent entries for analysis_results
                if table == 'analysis_results' and count > 0:
                    cursor.execute(f"""
                        SELECT system_id, analysis_type, timestamp 
                        FROM {table} 
                        ORDER BY timestamp DESC 
                        LIMIT 3
                    """)
                    recent = cursor.fetchall()
                    print(f"     Recent analyses:")
                    for system_id, analysis_type, timestamp in recent:
                        print(f"       {system_id} ({analysis_type}) - {timestamp}")
                        
            except Exception as e:
                print(f"   {table:20} | Error: {e}")
        
        print(f"   {'TOTAL':20} | {total_records:>6} records")
        conn.close()
        
    except Exception as e:
        print(f"âŒ Database analysis failed: {e}")
    
    # Test 6: System Configuration Review
    print("\nâš™ï¸ Test 6: Enhanced Configuration Review")
    print("-" * 50)
    
    try:
        config = system.config
        
        print(f"ğŸ“Š Enhanced System Configuration:")
        
        # Database settings
        print(f"   Database:")
        print(f"     Path: {config['database']['path']}")
        print(f"     Retention: {config['database']['retention_days']} days")
        
        # Monitoring settings
        print(f"   Monitoring:")
        print(f"     Analysis interval: {config['monitoring']['analysis_interval']}s")
        print(f"     Alert check interval: {config['monitoring']['alert_check_interval']}s")
        
        # Thresholds
        print(f"   Alert Thresholds:")
        print(f"     Health critical: {config['thresholds']['health_score_critical']}%")
        print(f"     Failure risk critical: {config['thresholds']['failure_risk_critical']}%")
        
        # Features
        print(f"   Features:")
        print(f"     ML enabled: {config['optimization']['ml_enabled']}")
        print(f"     Auto recommendations: {config['optimization']['auto_recommendations']}")
        print(f"     Email alerts: {config['alerts']['email_enabled']}")
        
    except Exception as e:
        print(f"âŒ Configuration review failed: {e}")
    
    print("\nğŸ‰ Enhanced Production System Test Completed!")
    print("=" * 70)
    
    # Summary
    print(f"ğŸŒŸ Enhanced Features Validated:")
    print(f"   âœ… Multi-string (32-string) analysis capability")
    print(f"   âœ… Multiple analysis type support")
    print(f"   âœ… Enhanced fleet management")
    print(f"   âœ… Advanced database storage")
    print(f"   âœ… Interactive dashboard generation")
    print(f"   âœ… Comprehensive configuration management")
    print(f"   âœ… Real-time alert system")
    print(f"   âœ… Production-ready deployment")
    
    return system

async def demonstrate_multi_string_capabilities():
    """Demonstrate specific multi-string analysis capabilities"""
    
    print("\nğŸ”Œ Multi-String Analysis Capabilities Demonstration")
    print("=" * 70)
    
    from multi_string_iv_analyzer import MultiStringIVAnalyzer
    from test_multi_string_analyzer import generate_multi_string_iv_data
    
    # Generate comprehensive test data
    print("ğŸ“Š Generating comprehensive 32-string test data...")
    
    # Create test scenarios
    scenarios = [
        {"name": "Balanced System", "variation": 0.05, "strings": 32},
        {"name": "Moderate Imbalance", "variation": 0.15, "strings": 24},
        {"name": "High Imbalance", "variation": 0.25, "strings": 16}
    ]
    
    for scenario in scenarios:
        print(f"\nğŸ¯ Scenario: {scenario['name']}")
        print(f"   Strings: {scenario['strings']}, Variation: {scenario['variation']*100:.0f}%")
        
        try:
            # Generate scenario data
            data_file, _ = generate_multi_string_iv_data(
                num_strings=scenario['strings'],
                num_points=100,
                variation_factor=scenario['variation'],
                output_file=f"scenario_{scenario['name'].lower().replace(' ', '_')}.csv"
            )
            
            # Analyze with multi-string analyzer
            analyzer = MultiStringIVAnalyzer(max_strings=32)
            result = analyzer.run_comprehensive_analysis(data_file)
            
            # Show key results
            print(f"   âœ… Analysis completed:")
            print(f"     Total Power: {result.system_performance['total_power_w']:.0f} W")
            print(f"     Average Efficiency: {result.system_performance['average_efficiency_pct']:.1f}%")
            print(f"     Imbalance Level: {result.imbalance_analysis['imbalance_severity']}")
            print(f"     Power CV: {result.imbalance_analysis['power_statistics']['cv']:.1f}%")
            print(f"     Recommendations: {len(result.optimization_recommendations)}")
            
        except Exception as e:
            print(f"   âŒ Scenario failed: {e}")
    
    print(f"\nğŸ‰ Multi-String Capabilities Demonstration Complete!")

if __name__ == "__main__":
    async def main():
        try:
            # Run enhanced production system test
            system = await test_enhanced_production_system()
            
            # Demonstrate multi-string capabilities
            await demonstrate_multi_string_capabilities()
            
            print("\nğŸš€ All Enhanced Tests Completed Successfully!")
            print("ğŸŒŸ System ready for enterprise deployment with multi-string support!")
            
        except Exception as e:
            print(f"âŒ Test failed with error: {e}")
            import traceback
            traceback.print_exc()
    
    # Run the async test
    asyncio.run(main())
